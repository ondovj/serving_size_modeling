{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Food Serving Sizes Through Nutrition Profiles\n",
    "\n",
    "### Notebook 3 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Importing Packages](#Importing-Packages)\n",
    "2. [Reading Data](#Reading-Data)\n",
    "3. [Feature Engineering](#Feature-Engineering)\n",
    "4. [Preprocessing](#Preprocessing)\n",
    "5. [Modeling](#Modeling)\n",
    "    1. [Baseline Model](#Baseline-Model)\n",
    "    2. [Linear Regression](#Linear-Regression)\n",
    "    3. [Ridge Regression](#Ridge-Regression)\n",
    "    4. [LASSO Regression](#LASSO-Regression)\n",
    "    5. [Neural Network](#Neural-Network)\n",
    "6. [Model Evaluations](#Model-Evaluations)\n",
    "    1. [R<sup>2</sup> Score](#R2-Score)\n",
    "    2. [Mean Squared Error](#Mean-Squared-Error)\n",
    "    3. [Visualizations](#Visualizations)\n",
    "7. [Conclusions and Recommendations](#Conclusions-and-Recommendations)\n",
    "    1. [Conclusions](#Conclusions)\n",
    "    2. [Recommendations](#Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools/visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "# imports for NLP\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# imports for modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Ridge, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "# making the magic happen for plots\n",
    "%matplotlib inline\n",
    "\n",
    "# setting options for better viewing\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "# setting global random seeds for numpy and tensorflow\n",
    "# np.random.seed(42)\n",
    "# set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point forward, we are going to utilize the combined and cleaned dataset from the end of the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.read_csv(\"../datasets/final_foods_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>branded_food_category</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>household_serving_fulltext</th>\n",
       "      <th>energy</th>\n",
       "      <th>fat_total</th>\n",
       "      <th>fat_sat</th>\n",
       "      <th>fat_trans</th>\n",
       "      <th>chol</th>\n",
       "      <th>protein</th>\n",
       "      <th>carbs</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356425</td>\n",
       "      <td>G. T. Japan, Inc.</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1 PIECE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356426</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356427</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.29</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356428</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.57</td>\n",
       "      <td>971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356429</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id        brand_owner                 branded_food_category  \\\n",
       "0  356425  G. T. Japan, Inc.             Ice Cream & Frozen Yogurt   \n",
       "1  356426       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "2  356427       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "3  356428       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "4  356429       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "\n",
       "                  description  \\\n",
       "0     MOCHI ICE CREAM BONBONS   \n",
       "1     CHIPOTLE BARBECUE SAUCE   \n",
       "2  HOT & SPICY BARBECUE SAUCE   \n",
       "3              BARBECUE SAUCE   \n",
       "4              BARBECUE SAUCE   \n",
       "\n",
       "                                         ingredients  serving_size  \\\n",
       "0  ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...          40.0   \n",
       "1  WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...          37.0   \n",
       "2  SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...          34.0   \n",
       "3  TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...          35.0   \n",
       "4  SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...          37.0   \n",
       "\n",
       "  household_serving_fulltext  energy  fat_total  fat_sat  fat_trans  chol  \\\n",
       "0                    1 PIECE   200.0       6.25     3.75        0.0  25.0   \n",
       "1                     2 Tbsp   162.0       0.00     0.00        0.0   0.0   \n",
       "2                     2 Tbsp   176.0       0.00     0.00        0.0   0.0   \n",
       "3                     2 Tbsp   143.0       0.00     0.00        0.0   0.0   \n",
       "4                     2 Tbsp   189.0       0.00     0.00        0.0   0.0   \n",
       "\n",
       "   protein  carbs  fiber  sugars  sodium  \n",
       "0      2.5  35.00    0.0   30.00    75.0  \n",
       "1      0.0  43.24    0.0   37.84   703.0  \n",
       "2      0.0  41.18    0.0   35.29   676.0  \n",
       "3      0.0  34.29    0.0   28.57   971.0  \n",
       "4      0.0  45.95    0.0   43.24   757.0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the modeling process begins, we need to fully prepare the dataset. In the previous notebook we had seen the tailed distribution of the serving size target, so we will make a new column here to use as the target for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods[\"log_serv\"] = np.log(foods[\"serving_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to use the category of the food product as a feature, we will have to turn them into dummy columns first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.get_dummies(data=foods,\n",
    "                       columns=[\"branded_food_category\"],\n",
    "                       prefix=\"cat\",\n",
    "                       drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>household_serving_fulltext</th>\n",
       "      <th>energy</th>\n",
       "      <th>fat_total</th>\n",
       "      <th>fat_sat</th>\n",
       "      <th>fat_trans</th>\n",
       "      <th>chol</th>\n",
       "      <th>protein</th>\n",
       "      <th>carbs</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>sodium</th>\n",
       "      <th>log_serv</th>\n",
       "      <th>cat_All Noodles</th>\n",
       "      <th>cat_Bacon, Sausages &amp; Ribs</th>\n",
       "      <th>cat_Baking</th>\n",
       "      <th>cat_Baking Accessories</th>\n",
       "      <th>cat_Baking Additives &amp; Extracts</th>\n",
       "      <th>cat_Baking Decorations &amp; Dessert Toppings</th>\n",
       "      <th>cat_Baking/Cooking Mixes (Perishable)</th>\n",
       "      <th>cat_Baking/Cooking Mixes (Shelf Stable)</th>\n",
       "      <th>cat_Baking/Cooking Mixes/Supplies Variety Packs</th>\n",
       "      <th>cat_Baking/Cooking Supplies (Shelf Stable)</th>\n",
       "      <th>cat_Beef - Prepared/Processed</th>\n",
       "      <th>cat_Biscuits/Cookies (Shelf Stable)</th>\n",
       "      <th>cat_Bread &amp; Muffin Mixes</th>\n",
       "      <th>cat_Breads &amp; Buns</th>\n",
       "      <th>cat_Breakfast Drinks</th>\n",
       "      <th>cat_Breakfast Foods</th>\n",
       "      <th>cat_Breakfast Sandwiches, Biscuits &amp; Meals</th>\n",
       "      <th>cat_Butter &amp; Spread</th>\n",
       "      <th>cat_Cake, Cookie &amp; Cupcake Mixes</th>\n",
       "      <th>cat_Cakes - Sweet (Frozen)</th>\n",
       "      <th>cat_Cakes - Sweet (Shelf Stable)</th>\n",
       "      <th>cat_Cakes, Cupcakes, Snack Cakes</th>\n",
       "      <th>cat_Candy</th>\n",
       "      <th>cat_Canned &amp; Bottled Beans</th>\n",
       "      <th>cat_Canned Condensed Soup</th>\n",
       "      <th>cat_Canned Fruit</th>\n",
       "      <th>cat_Canned Meat</th>\n",
       "      <th>cat_Canned Seafood</th>\n",
       "      <th>cat_Canned Soup</th>\n",
       "      <th>cat_Canned Tuna</th>\n",
       "      <th>cat_Canned Vegetables</th>\n",
       "      <th>cat_Cereal</th>\n",
       "      <th>cat_Cereal/Muesli Bars</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_Pancakes, Waffles, French Toast &amp; Crepes</th>\n",
       "      <th>cat_Pasta Dinners</th>\n",
       "      <th>cat_Pasta by Shape &amp; Type</th>\n",
       "      <th>cat_Pasta/Noodles - Not Ready to Eat (Frozen)</th>\n",
       "      <th>cat_Pastry Shells &amp; Fillings</th>\n",
       "      <th>cat_Pepperoni, Salami &amp; Cold Cuts</th>\n",
       "      <th>cat_Pickles, Olives, Peppers &amp; Relishes</th>\n",
       "      <th>cat_Pies/Pastries - Sweet (Shelf Stable)</th>\n",
       "      <th>cat_Pies/Pastries/Pizzas/Quiches - Savoury (Frozen)</th>\n",
       "      <th>cat_Pizza</th>\n",
       "      <th>cat_Pizza Mixes &amp; Other Dry Dinners</th>\n",
       "      <th>cat_Plant Based Milk</th>\n",
       "      <th>cat_Plant Based Water</th>\n",
       "      <th>cat_Popcorn (Shelf Stable)</th>\n",
       "      <th>cat_Popcorn, Peanuts, Seeds &amp; Related Snacks</th>\n",
       "      <th>cat_Pork Sausages - Prepared/Processed</th>\n",
       "      <th>cat_Poultry, Chicken &amp; Turkey</th>\n",
       "      <th>cat_Powdered Drinks</th>\n",
       "      <th>cat_Pre-Packaged Fruit &amp; Vegetables</th>\n",
       "      <th>cat_Prepared Pasta &amp; Pizza Sauces</th>\n",
       "      <th>cat_Prepared Subs &amp; Sandwiches</th>\n",
       "      <th>cat_Prepared Wraps and Burittos</th>\n",
       "      <th>cat_Processed Cheese &amp; Cheese Novelties</th>\n",
       "      <th>cat_Puddings &amp; Custards</th>\n",
       "      <th>cat_Rice</th>\n",
       "      <th>cat_Salad Dressing &amp; Mayonnaise</th>\n",
       "      <th>cat_Sausages, Hotdogs &amp; Brats</th>\n",
       "      <th>cat_Seasoning Mixes, Salts, Marinades &amp; Tenderizers</th>\n",
       "      <th>cat_Snack, Energy &amp; Granola Bars</th>\n",
       "      <th>cat_Soda</th>\n",
       "      <th>cat_Soups - Prepared (Shelf Stable)</th>\n",
       "      <th>cat_Specialty Formula Supplements</th>\n",
       "      <th>cat_Sport Drinks</th>\n",
       "      <th>cat_Stuffing</th>\n",
       "      <th>cat_Sushi</th>\n",
       "      <th>cat_Syrups &amp; Molasses</th>\n",
       "      <th>cat_Tea Bags</th>\n",
       "      <th>cat_Tomatoes</th>\n",
       "      <th>cat_Vegetable &amp; Cooking Oils</th>\n",
       "      <th>cat_Vegetable Based Products / Meals - Not Ready to Eat (Frozen)</th>\n",
       "      <th>cat_Vegetable and Lentil Mixes</th>\n",
       "      <th>cat_Vegetables - Prepared/Processed (Frozen)</th>\n",
       "      <th>cat_Vegetables - Prepared/Processed (Shelf Stable)</th>\n",
       "      <th>cat_Vegetarian Frozen Meats</th>\n",
       "      <th>cat_Vitamins</th>\n",
       "      <th>cat_Water</th>\n",
       "      <th>cat_Weight Control</th>\n",
       "      <th>cat_Wholesome Snacks</th>\n",
       "      <th>cat_Yogurt</th>\n",
       "      <th>cat_Yogurt/Yogurt Substitutes (Perishable)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356425</td>\n",
       "      <td>G. T. Japan, Inc.</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1 PIECE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356426</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>703.0</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356427</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.29</td>\n",
       "      <td>676.0</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356428</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.57</td>\n",
       "      <td>971.0</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356429</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>757.0</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id        brand_owner                 description  \\\n",
       "0  356425  G. T. Japan, Inc.     MOCHI ICE CREAM BONBONS   \n",
       "1  356426       FRESH & EASY     CHIPOTLE BARBECUE SAUCE   \n",
       "2  356427       FRESH & EASY  HOT & SPICY BARBECUE SAUCE   \n",
       "3  356428       FRESH & EASY              BARBECUE SAUCE   \n",
       "4  356429       FRESH & EASY              BARBECUE SAUCE   \n",
       "\n",
       "                                         ingredients  serving_size  \\\n",
       "0  ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...          40.0   \n",
       "1  WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...          37.0   \n",
       "2  SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...          34.0   \n",
       "3  TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...          35.0   \n",
       "4  SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...          37.0   \n",
       "\n",
       "  household_serving_fulltext  energy  fat_total  fat_sat  fat_trans  chol  \\\n",
       "0                    1 PIECE   200.0       6.25     3.75        0.0  25.0   \n",
       "1                     2 Tbsp   162.0       0.00     0.00        0.0   0.0   \n",
       "2                     2 Tbsp   176.0       0.00     0.00        0.0   0.0   \n",
       "3                     2 Tbsp   143.0       0.00     0.00        0.0   0.0   \n",
       "4                     2 Tbsp   189.0       0.00     0.00        0.0   0.0   \n",
       "\n",
       "   protein  carbs  fiber  sugars  sodium  log_serv  cat_All Noodles  \\\n",
       "0      2.5  35.00    0.0   30.00    75.0  3.688879                0   \n",
       "1      0.0  43.24    0.0   37.84   703.0  3.610918                0   \n",
       "2      0.0  41.18    0.0   35.29   676.0  3.526361                0   \n",
       "3      0.0  34.29    0.0   28.57   971.0  3.555348                0   \n",
       "4      0.0  45.95    0.0   43.24   757.0  3.610918                0   \n",
       "\n",
       "   cat_Bacon, Sausages & Ribs  cat_Baking  cat_Baking Accessories  \\\n",
       "0                           0           0                       0   \n",
       "1                           0           0                       0   \n",
       "2                           0           0                       0   \n",
       "3                           0           0                       0   \n",
       "4                           0           0                       0   \n",
       "\n",
       "   cat_Baking Additives & Extracts  cat_Baking Decorations & Dessert Toppings  \\\n",
       "0                                0                                          0   \n",
       "1                                0                                          0   \n",
       "2                                0                                          0   \n",
       "3                                0                                          0   \n",
       "4                                0                                          0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes (Perishable)  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes (Shelf Stable)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes/Supplies Variety Packs  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   cat_Baking/Cooking Supplies (Shelf Stable)  cat_Beef - Prepared/Processed  \\\n",
       "0                                           0                              0   \n",
       "1                                           0                              0   \n",
       "2                                           0                              0   \n",
       "3                                           0                              0   \n",
       "4                                           0                              0   \n",
       "\n",
       "   cat_Biscuits/Cookies (Shelf Stable)  cat_Bread & Muffin Mixes  \\\n",
       "0                                    0                         0   \n",
       "1                                    0                         0   \n",
       "2                                    0                         0   \n",
       "3                                    0                         0   \n",
       "4                                    0                         0   \n",
       "\n",
       "   cat_Breads & Buns  cat_Breakfast Drinks  cat_Breakfast Foods  \\\n",
       "0                  0                     0                    0   \n",
       "1                  0                     0                    0   \n",
       "2                  0                     0                    0   \n",
       "3                  0                     0                    0   \n",
       "4                  0                     0                    0   \n",
       "\n",
       "   cat_Breakfast Sandwiches, Biscuits & Meals  cat_Butter & Spread  \\\n",
       "0                                           0                    0   \n",
       "1                                           0                    0   \n",
       "2                                           0                    0   \n",
       "3                                           0                    0   \n",
       "4                                           0                    0   \n",
       "\n",
       "   cat_Cake, Cookie & Cupcake Mixes  cat_Cakes - Sweet (Frozen)  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   cat_Cakes - Sweet (Shelf Stable)  cat_Cakes, Cupcakes, Snack Cakes  \\\n",
       "0                                 0                                 0   \n",
       "1                                 0                                 0   \n",
       "2                                 0                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                 0                                 0   \n",
       "\n",
       "   cat_Candy  cat_Canned & Bottled Beans  cat_Canned Condensed Soup  \\\n",
       "0          0                           0                          0   \n",
       "1          0                           0                          0   \n",
       "2          0                           0                          0   \n",
       "3          0                           0                          0   \n",
       "4          0                           0                          0   \n",
       "\n",
       "   cat_Canned Fruit  cat_Canned Meat  cat_Canned Seafood  cat_Canned Soup  \\\n",
       "0                 0                0                   0                0   \n",
       "1                 0                0                   0                0   \n",
       "2                 0                0                   0                0   \n",
       "3                 0                0                   0                0   \n",
       "4                 0                0                   0                0   \n",
       "\n",
       "   cat_Canned Tuna  cat_Canned Vegetables  cat_Cereal  cat_Cereal/Muesli Bars  \\\n",
       "0                0                      0           0                       0   \n",
       "1                0                      0           0                       0   \n",
       "2                0                      0           0                       0   \n",
       "3                0                      0           0                       0   \n",
       "4                0                      0           0                       0   \n",
       "\n",
       "   ...  cat_Pancakes, Waffles, French Toast & Crepes  cat_Pasta Dinners  \\\n",
       "0  ...                                             0                  0   \n",
       "1  ...                                             0                  0   \n",
       "2  ...                                             0                  0   \n",
       "3  ...                                             0                  0   \n",
       "4  ...                                             0                  0   \n",
       "\n",
       "   cat_Pasta by Shape & Type  cat_Pasta/Noodles - Not Ready to Eat (Frozen)  \\\n",
       "0                          0                                              0   \n",
       "1                          0                                              0   \n",
       "2                          0                                              0   \n",
       "3                          0                                              0   \n",
       "4                          0                                              0   \n",
       "\n",
       "   cat_Pastry Shells & Fillings  cat_Pepperoni, Salami & Cold Cuts  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "\n",
       "   cat_Pickles, Olives, Peppers & Relishes  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   cat_Pies/Pastries - Sweet (Shelf Stable)  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   cat_Pies/Pastries/Pizzas/Quiches - Savoury (Frozen)  cat_Pizza  \\\n",
       "0                                                  0            0   \n",
       "1                                                  0            0   \n",
       "2                                                  0            0   \n",
       "3                                                  0            0   \n",
       "4                                                  0            0   \n",
       "\n",
       "   cat_Pizza Mixes & Other Dry Dinners  cat_Plant Based Milk  \\\n",
       "0                                    0                     0   \n",
       "1                                    0                     0   \n",
       "2                                    0                     0   \n",
       "3                                    0                     0   \n",
       "4                                    0                     0   \n",
       "\n",
       "   cat_Plant Based Water  cat_Popcorn (Shelf Stable)  \\\n",
       "0                      0                           0   \n",
       "1                      0                           0   \n",
       "2                      0                           0   \n",
       "3                      0                           0   \n",
       "4                      0                           0   \n",
       "\n",
       "   cat_Popcorn, Peanuts, Seeds & Related Snacks  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   cat_Pork Sausages - Prepared/Processed  cat_Poultry, Chicken & Turkey  \\\n",
       "0                                       0                              0   \n",
       "1                                       0                              0   \n",
       "2                                       0                              0   \n",
       "3                                       0                              0   \n",
       "4                                       0                              0   \n",
       "\n",
       "   cat_Powdered Drinks  cat_Pre-Packaged Fruit & Vegetables  \\\n",
       "0                    0                                    0   \n",
       "1                    0                                    0   \n",
       "2                    0                                    0   \n",
       "3                    0                                    0   \n",
       "4                    0                                    0   \n",
       "\n",
       "   cat_Prepared Pasta & Pizza Sauces  cat_Prepared Subs & Sandwiches  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   cat_Prepared Wraps and Burittos  cat_Processed Cheese & Cheese Novelties  \\\n",
       "0                                0                                        0   \n",
       "1                                0                                        0   \n",
       "2                                0                                        0   \n",
       "3                                0                                        0   \n",
       "4                                0                                        0   \n",
       "\n",
       "   cat_Puddings & Custards  cat_Rice  cat_Salad Dressing & Mayonnaise  \\\n",
       "0                        0         0                                0   \n",
       "1                        0         0                                0   \n",
       "2                        0         0                                0   \n",
       "3                        0         0                                0   \n",
       "4                        0         0                                0   \n",
       "\n",
       "   cat_Sausages, Hotdogs & Brats  \\\n",
       "0                              0   \n",
       "1                              0   \n",
       "2                              0   \n",
       "3                              0   \n",
       "4                              0   \n",
       "\n",
       "   cat_Seasoning Mixes, Salts, Marinades & Tenderizers  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   cat_Snack, Energy & Granola Bars  cat_Soda  \\\n",
       "0                                 0         0   \n",
       "1                                 0         0   \n",
       "2                                 0         0   \n",
       "3                                 0         0   \n",
       "4                                 0         0   \n",
       "\n",
       "   cat_Soups - Prepared (Shelf Stable)  cat_Specialty Formula Supplements  \\\n",
       "0                                    0                                  0   \n",
       "1                                    0                                  0   \n",
       "2                                    0                                  0   \n",
       "3                                    0                                  0   \n",
       "4                                    0                                  0   \n",
       "\n",
       "   cat_Sport Drinks  cat_Stuffing  cat_Sushi  cat_Syrups & Molasses  \\\n",
       "0                 0             0          0                      0   \n",
       "1                 0             0          0                      0   \n",
       "2                 0             0          0                      0   \n",
       "3                 0             0          0                      0   \n",
       "4                 0             0          0                      0   \n",
       "\n",
       "   cat_Tea Bags  cat_Tomatoes  cat_Vegetable & Cooking Oils  \\\n",
       "0             0             0                             0   \n",
       "1             0             0                             0   \n",
       "2             0             0                             0   \n",
       "3             0             0                             0   \n",
       "4             0             0                             0   \n",
       "\n",
       "   cat_Vegetable Based Products / Meals - Not Ready to Eat (Frozen)  \\\n",
       "0                                                  0                  \n",
       "1                                                  0                  \n",
       "2                                                  0                  \n",
       "3                                                  0                  \n",
       "4                                                  0                  \n",
       "\n",
       "   cat_Vegetable and Lentil Mixes  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                               0   \n",
       "4                               0   \n",
       "\n",
       "   cat_Vegetables - Prepared/Processed (Frozen)  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   cat_Vegetables - Prepared/Processed (Shelf Stable)  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   cat_Vegetarian Frozen Meats  cat_Vitamins  cat_Water  cat_Weight Control  \\\n",
       "0                            0             0          0                   0   \n",
       "1                            0             0          0                   0   \n",
       "2                            0             0          0                   0   \n",
       "3                            0             0          0                   0   \n",
       "4                            0             0          0                   0   \n",
       "\n",
       "   cat_Wholesome Snacks  cat_Yogurt  \\\n",
       "0                     0           0   \n",
       "1                     0           0   \n",
       "2                     0           0   \n",
       "3                     0           0   \n",
       "4                     0           0   \n",
       "\n",
       "   cat_Yogurt/Yogurt Substitutes (Perishable)  \n",
       "0                                           0  \n",
       "1                                           0  \n",
       "2                                           0  \n",
       "3                                           0  \n",
       "4                                           0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for new cols\n",
    "foods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing steps here are to split our dataset into the X features and y target, and then scale the features so they can be flexibly used across different model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y vars\n",
    "X = foods.drop(columns=[\"fdc_id\", \n",
    "                        \"brand_owner\", \n",
    "                        \"description\", \n",
    "                        \"ingredients\", \n",
    "                        \"household_serving_fulltext\",\n",
    "                        \"serving_size\",\n",
    "                       \"log_serv\"])\n",
    "y = foods[\"log_serv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# instantiating scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# scaling X data\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been fully prepared, we can beign the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way of predicting serving size without using any machine learning, by simply using the mean of the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Train MSE Score for our Base Model is: 3685.336822662155\n",
      "Our Test MSE Score for our Base Model is: 3833.116046199187\n"
     ]
    }
   ],
   "source": [
    "# building a base model to compare results against\n",
    "# using code from Boom's Local Session\n",
    "\n",
    "# Instantiate: creates a dummy regression that always predicts the mean of the target\n",
    "base_mean = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Fit the \"model\"\n",
    "base_mean = base_mean.fit(X_train_sc, y_train)\n",
    "\n",
    "# Get predictions for our testing set (not kaggle testing set)\n",
    "y_hat_base_train = base_mean.predict(X_train_sc)\n",
    "y_hat_base_test = base_mean.predict(X_test_sc)\n",
    "\n",
    "# Get R2\n",
    "print(\"Our Train MSE Score for our Base Model is:\", metrics.mean_squared_error(np.exp(y_train),np.exp(y_hat_base_train)))\n",
    "print(\"Our Test MSE Score for our Base Model is:\",  metrics.mean_squared_error(np.exp(y_test),np.exp(y_hat_base_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.766648751921747"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.766648751922297"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_base_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.773870919807258"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88488     5.501258\n",
       "179653    4.510860\n",
       "169634    3.806662\n",
       "45499     3.044522\n",
       "113786    3.218876\n",
       "            ...   \n",
       "165996    4.510860\n",
       "105540    4.219508\n",
       "87477     5.220356\n",
       "128007    4.510860\n",
       "57841     3.784190\n",
       "Name: log_serv, Length: 47287, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.766648751922298"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_base_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.76664875, 3.76664875, 3.76664875, ..., 3.76664875, 3.76664875,\n",
       "       3.76664875])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_base_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The help find the best possible model parameters, we should build a function to perform gridsearches for us. We can then implement this function on any model type and set of parameters to optimize each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bringing in func from Reddit NLP project\n",
    "def grid_searcher(pipe, params):\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=params, cv=3, verbose=1, n_jobs=3)\n",
    "    gs.fit(X_train_sc, y_train)\n",
    "    print(f'CrossVal Score: {gs.best_score_}')\n",
    "    print(f'Training Score: {gs.score(X_train_sc, y_train)}')\n",
    "    print(f'Testing Score: {gs.score(X_test_sc, y_test)}')\n",
    "    print(gs.best_params_)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linear regression is a very simple model, there is really no hyperparameter searching that needs to be performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg_model = linreg.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.735346306445012.\n",
      "The test R2 score is: -2.465033209278544e+18.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train R2 score is: {linreg_model.score(X_train_sc, y_train)}.\")\n",
    "print(f\"The test R2 score is: {linreg_model.score(X_test_sc, y_test)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic linear regression model is not scoring very high, although it is also showing a fairly low variance. Since we did see some multicolinearity in a few of the features during the EDA, it may be worth looking at a LASSO or ridge regression for some improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `LassoCV` model already iterates through a list of 100 alphas, we do not need torun the gridsearching function on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV()\n",
    "lasso_model = lasso.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.7351460362337019.\n",
      "The test R2 score is: 0.7403776480182412.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train R2 score is: {lasso_model.score(X_train_sc, y_train)}.\")\n",
    "print(f\"The test R2 score is: {lasso_model.score(X_test_sc, y_test)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([(\"ridge\", Ridge())])\n",
    "\n",
    "ridge_params = {\n",
    "    \"ridge__alpha\": [11, 12, 13]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossVal Score: 0.7338202830606281\n",
      "Training Score: 0.7353441884095184\n",
      "Testing Score: 0.7406257916854004\n",
      "{'ridge__alpha': 12}\n"
     ]
    }
   ],
   "source": [
    "ridge_model = grid_searcher(ridge_pipe, ridge_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these regularization methods had any large impact on the R<sup>2</sup> scores. These model are typically most helpful to regularize overfit linear regressions, and as our initial model was not very overfit, they may not just not be enough of an improvement. We may need to utilize a more advanced regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks \n",
    "\n",
    "As using a Neural Network was showing promise as the best model type to use, we should have a way of effectively optimizing it. While a Keras Sequential model cannot be passed through Scikit-learn's `GridSearchCV`, we can make our own custom function to essentially perform the same type of task. To that end, the following functions were created, which were adapted from code written by Mahdi Shadkam-Farrokhi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_params(grid_params):\n",
    "    '''Returns a list of all combinations of unique parameters from the given dictionary'''\n",
    "    out = [{}]\n",
    "    for param_name, param_list in grid_params.items():\n",
    "        if len(param_list) == 1:\n",
    "            for item in out:\n",
    "                item[param_name] = param_list[0]\n",
    "        else:\n",
    "            temp_out = []\n",
    "            for param_val in param_list:\n",
    "                for item in out:\n",
    "                    cloned_item = item.copy()\n",
    "                    cloned_item[param_name] = param_val\n",
    "                    temp_out.append(cloned_item)\n",
    "            out = temp_out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next piece is to take a dictionary of parameters and build a functioning model out of it. We will make a model building fucntion to perfrom this action. It will take our train/test split data, and a dictionary of the parameters that has the specified keys. The function will reach into each of the keys for the appropriate attribute, and then apply that to the coresponding layer. To increase flexibility, there will be default settings for each of the parameters, so that the dictioanry does not have to contain entries for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params_dict, X_train, X_test, y_train, y_test):\n",
    "    # defining params\n",
    "    first_layer_nodes = params_dict.get(\"first_layer_nodes\") or 16            # default low nodes\n",
    "    first_dropout_rate = params_dict.get(\"first_dropout_rate\") or 0.0         # default no dropout\n",
    "    second_layer_nodes = params_dict.get(\"second_layer_nodes\") or 16          # default low nodes\n",
    "    second_dropout_rate = params_dict.get(\"second_dropout_rate\") or 0.0       # default no dropout\n",
    "    third_layer_nodes = params_dict.get(\"third_layer_nodes\") or 16            # default low nodes\n",
    "    third_dropout_rate = params_dict.get(\"third_dropout_rate\") or 0.0         # default no dropout  \n",
    "    reg = params_dict.get(\"reg\") or 0                                         # default no reg\n",
    "    epochs = params_dict.get(\"epochs\") or 10                                  # default low epochs\n",
    "    batch_size = params_dict.get(\"batch_size\") or 1024                        # default large batch\n",
    "    early_stop = params_dict.get(\"early_stop\") or EarlyStopping(monitor=\"val_loss\",\n",
    "                                                                min_delta=0.000000001,  # small delta\n",
    "                                                                patience=100)           # large patience\n",
    "    \n",
    "    # instantiating model\n",
    "    model = Sequential()\n",
    "\n",
    "    # adding layers\n",
    "    model.add(Dense(first_layer_nodes,\n",
    "                   activation=\"relu\",\n",
    "                   input_shape=(X_train.shape[1],),\n",
    "                   kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(first_dropout_rate))\n",
    "    model.add(Dense(second_layer_nodes,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(second_dropout_rate))\n",
    "    model.add(Dense(third_layer_nodes,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(third_dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\",\n",
    "             optimizer=\"adam\")\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                       callbacks=[early_stop])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_grid_search(\n",
    "    X,\n",
    "    y,\n",
    "    grid_params,\n",
    "    random_state = 42\n",
    "):\n",
    "    ### this \n",
    "    \n",
    "    # list of all parameter combinations\n",
    "    all_params = permutate_params(grid_params)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0.0 # no accuracy to start\n",
    "    best_params = None\n",
    "    best_history = None\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    ss = StandardScaler()\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    \n",
    "    for i, params in enumerate(all_params):\n",
    "        print(f\"Building model {i + 1} of {len(all_params)}\")\n",
    "        model, history = build_model(\n",
    "            params_dict = params,\n",
    "            X_train = X_train_sc, \n",
    "            X_test = X_test_sc, \n",
    "            y_train = y_train, \n",
    "            y_test = y_test\n",
    "        )\n",
    "\n",
    "        test_preds = model.predict(X_test_sc)\n",
    "        score = metrics.r2_score(y_test, test_preds)\n",
    "        \n",
    "        if score > best_score:\n",
    "            print(\"***Good R2 found: {:.2%}***\".format(score))\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "            best_history = history\n",
    "    return {\n",
    "        \"best_model\"   : best_model,\n",
    "        \"best_score\"   : best_score,\n",
    "        \"best_params\"  : best_params,\n",
    "        \"best_history\" : best_history,\n",
    "        \"test_preds\"   : test_preds\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our functions built, we can run the search. We will start with finding the best number of nodes out of three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting params\n",
    "node_params = {\n",
    "    \"first_layer_nodes\": [256, 128, 64],\n",
    "    \"second_layer_nodes\": [128, 64, 32],\n",
    "    \"third_layer_nodes\": [64, 32, 16],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model 1 of 27\n",
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.8480 - val_loss: 0.2177\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2511 - val_loss: 0.1866\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1780 - val_loss: 0.1720\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1655 - val_loss: 0.1588\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1560 - val_loss: 0.1517\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1503 - val_loss: 0.1508\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1458 - val_loss: 0.1423\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1418 - val_loss: 0.1390\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1377 - val_loss: 0.1373\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1360 - val_loss: 0.1363\n",
      "***Good R2 found: 86.64%***\n",
      "Building model 2 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.6750 - val_loss: 0.2131\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1966 - val_loss: 0.1820\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1701 - val_loss: 0.1625\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1596 - val_loss: 0.1563\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1536 - val_loss: 0.1516\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1500 - val_loss: 0.1506\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1465 - val_loss: 0.1455\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1414 - val_loss: 0.1404\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1385 - val_loss: 0.1381\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1358 - val_loss: 0.1349\n",
      "***Good R2 found: 86.77%***\n",
      "Building model 3 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 1.8887 - val_loss: 0.2434\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.2262 - val_loss: 0.1876\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1775 - val_loss: 0.1716\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1649 - val_loss: 0.1607\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1595 - val_loss: 0.1560\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1584 - val_loss: 0.1604\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1560 - val_loss: 0.1686\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1551 - val_loss: 0.1561\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1495 - val_loss: 0.1476\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1423 - val_loss: 0.1408\n",
      "Building model 4 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.1263 - val_loss: 0.2058\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1876 - val_loss: 0.1775\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1688 - val_loss: 0.1633\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1596 - val_loss: 0.1583\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1531 - val_loss: 0.1537\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1511 - val_loss: 0.1490\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1458 - val_loss: 0.1430\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1392 - val_loss: 0.1381\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1371 - val_loss: 0.1364\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1352 - val_loss: 0.1347\n",
      "***Good R2 found: 86.79%***\n",
      "Building model 5 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 1.4174 - val_loss: 0.2229\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2002 - val_loss: 0.1801\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1747 - val_loss: 0.1670\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1618 - val_loss: 0.1564\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1543 - val_loss: 0.1570\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1522 - val_loss: 0.1539\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1494 - val_loss: 0.1484\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1466 - val_loss: 0.1495\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1467 - val_loss: 0.1412\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1405 - val_loss: 0.1439\n",
      "Building model 6 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 2.0023 - val_loss: 0.3035\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.2403 - val_loss: 0.1988\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1867 - val_loss: 0.1777\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1717 - val_loss: 0.1662\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1634 - val_loss: 0.1605\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1586 - val_loss: 0.1606\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1550 - val_loss: 0.1534\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1504 - val_loss: 0.1475\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1483 - val_loss: 0.1457\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1435 - val_loss: 0.1432\n",
      "Building model 7 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 2.0452 - val_loss: 0.2245\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.2066 - val_loss: 0.1819\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1757 - val_loss: 0.1665\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1653 - val_loss: 0.1623\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1592 - val_loss: 0.1522\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1502 - val_loss: 0.1477\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1452 - val_loss: 0.1439\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1406 - val_loss: 0.1407\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1368 - val_loss: 0.1380\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1348 - val_loss: 0.1362\n",
      "Building model 8 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 1.3688 - val_loss: 0.2637\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.2189 - val_loss: 0.1904\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1802 - val_loss: 0.1726\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1657 - val_loss: 0.1593\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1578 - val_loss: 0.1545\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1533 - val_loss: 0.1490\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1492 - val_loss: 0.1507\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1463 - val_loss: 0.1430\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1429 - val_loss: 0.1455\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1418 - val_loss: 0.1407\n",
      "Building model 9 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 2.3154 - val_loss: 0.2661\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.2709 - val_loss: 0.1995\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1925 - val_loss: 0.1769\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1718 - val_loss: 0.1672\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1626 - val_loss: 0.1585\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1561 - val_loss: 0.1568\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1522 - val_loss: 0.1510\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1481 - val_loss: 0.1485\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1453 - val_loss: 0.1449\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1419 - val_loss: 0.1441\n",
      "Building model 10 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.9390 - val_loss: 0.2028\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1902 - val_loss: 0.1766\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1731 - val_loss: 0.1704\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1652 - val_loss: 0.1546\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1564 - val_loss: 0.1448\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1457 - val_loss: 0.1430\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1390 - val_loss: 0.1401\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1350 - val_loss: 0.1352\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1312 - val_loss: 0.1321\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1290 - val_loss: 0.1318\n",
      "***Good R2 found: 87.08%***\n",
      "Building model 11 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.4023 - val_loss: 0.2055\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1985 - val_loss: 0.1762\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1694 - val_loss: 0.1642\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1592 - val_loss: 0.1569\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1540 - val_loss: 0.1523\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1482 - val_loss: 0.1480\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1445 - val_loss: 0.1440\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1405 - val_loss: 0.1410\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1366 - val_loss: 0.1385\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1343 - val_loss: 0.1378\n",
      "Building model 12 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 1.5955 - val_loss: 0.3439\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.2564 - val_loss: 0.1961\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1840 - val_loss: 0.1755\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1703 - val_loss: 0.1636\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1632 - val_loss: 0.1614\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1608 - val_loss: 0.1592\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1561 - val_loss: 0.1609\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1531 - val_loss: 0.1468\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1470 - val_loss: 0.1490\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1451 - val_loss: 0.1436\n",
      "Building model 13 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.9593 - val_loss: 0.2080\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1920 - val_loss: 0.1777\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1833 - val_loss: 0.1642\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1673 - val_loss: 0.1530\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1594 - val_loss: 0.1512\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.1503 - val_loss: 0.1466\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1416 - val_loss: 0.1405\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1365 - val_loss: 0.1391\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1343 - val_loss: 0.1399\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1323 - val_loss: 0.1331\n",
      "Building model 14 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.6498 - val_loss: 0.2255\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2128 - val_loss: 0.1855\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1786 - val_loss: 0.1697\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1663 - val_loss: 0.1644\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1611 - val_loss: 0.1592\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1570 - val_loss: 0.1519\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1522 - val_loss: 0.1479\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1476 - val_loss: 0.1437\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1417 - val_loss: 0.1404\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1365 - val_loss: 0.1378\n",
      "Building model 15 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 1.8320 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.2465 - val_loss: 0.1952\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1865 - val_loss: 0.1779\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1729 - val_loss: 0.1673\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1654 - val_loss: 0.1621\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1617 - val_loss: 0.1564\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1576 - val_loss: 0.1515\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1515 - val_loss: 0.1486\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1490 - val_loss: 0.1451\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1452 - val_loss: 0.1425\n",
      "Building model 16 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 2.1269 - val_loss: 0.2366\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2790 - val_loss: 0.1872\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1836 - val_loss: 0.1707\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1694 - val_loss: 0.1613\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1593 - val_loss: 0.1573\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1548 - val_loss: 0.1539\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1539 - val_loss: 0.1479\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1537 - val_loss: 0.1468\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1431 - val_loss: 0.1461\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1407 - val_loss: 0.1402\n",
      "Building model 17 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.8820 - val_loss: 0.2412\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.2116 - val_loss: 0.1860\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1779 - val_loss: 0.1711\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1676 - val_loss: 0.1645\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1597 - val_loss: 0.1583\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1550 - val_loss: 0.1535\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1513 - val_loss: 0.1504\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1474 - val_loss: 0.1500\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1451 - val_loss: 0.1509\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1441 - val_loss: 0.1488\n",
      "Building model 18 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 2.2923 - val_loss: 0.2695\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.2562 - val_loss: 0.1983\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1931 - val_loss: 0.1785\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1741 - val_loss: 0.1697\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1669 - val_loss: 0.1652\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1622 - val_loss: 0.1606\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1586 - val_loss: 0.1551\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1542 - val_loss: 0.1574\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1546 - val_loss: 0.1584\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1500 - val_loss: 0.1486\n",
      "Building model 19 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.3319 - val_loss: 0.2192\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1889 - val_loss: 0.1745\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1696 - val_loss: 0.1620\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1588 - val_loss: 0.1544\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1529 - val_loss: 0.1546\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1515 - val_loss: 0.1508\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1483 - val_loss: 0.1456\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1428 - val_loss: 0.1430\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1383 - val_loss: 0.1394\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1365 - val_loss: 0.1413\n",
      "Building model 20 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 1.6037 - val_loss: 0.2206\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2216 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1984 - val_loss: 0.1723\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1689 - val_loss: 0.1615\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1585 - val_loss: 0.1543\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1536 - val_loss: 0.1506\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1491 - val_loss: 0.1483\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1448 - val_loss: 0.1455\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1428 - val_loss: 0.1431\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1406 - val_loss: 0.1500\n",
      "Building model 21 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 2.5000 - val_loss: 0.2576\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2320 - val_loss: 0.1971\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1888 - val_loss: 0.1778\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1740 - val_loss: 0.1683\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1660 - val_loss: 0.1623\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1611 - val_loss: 0.1572\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1558 - val_loss: 0.1564\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1515 - val_loss: 0.1495\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1484 - val_loss: 0.1475\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1458 - val_loss: 0.1455\n",
      "Building model 22 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.5932 - val_loss: 0.2246\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.2030 - val_loss: 0.1874\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1801 - val_loss: 0.1745\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1720 - val_loss: 0.1645\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1644 - val_loss: 0.1574\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1549 - val_loss: 0.1536\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1493 - val_loss: 0.1465\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1455 - val_loss: 0.1441\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1429 - val_loss: 0.1406\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1400 - val_loss: 0.1413\n",
      "Building model 23 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 1.2414 - val_loss: 0.2272\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.2060 - val_loss: 0.1958\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1791 - val_loss: 0.1726\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1636 - val_loss: 0.1579\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1547 - val_loss: 0.1540\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1511 - val_loss: 0.1498\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1463 - val_loss: 0.1441\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1433 - val_loss: 0.1448\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1458 - val_loss: 0.1416\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1364 - val_loss: 0.1404\n",
      "Building model 24 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 2.2707 - val_loss: 0.2776\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.2601 - val_loss: 0.2213\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1947 - val_loss: 0.1782\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1739 - val_loss: 0.1680\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1658 - val_loss: 0.1612\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1601 - val_loss: 0.1583\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1573 - val_loss: 0.1581\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1623 - val_loss: 0.1626\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1538 - val_loss: 0.1523\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1497 - val_loss: 0.1518\n",
      "Building model 25 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 1.4883 - val_loss: 0.3015\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2344 - val_loss: 0.2097\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1785 - val_loss: 0.1678\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1649 - val_loss: 0.1590\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1580 - val_loss: 0.1541\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1510 - val_loss: 0.1490\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1467 - val_loss: 0.1477\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1455 - val_loss: 0.1432\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1404 - val_loss: 0.1399\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1377 - val_loss: 0.1370\n",
      "Building model 26 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 2.2189 - val_loss: 0.2291\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2075 - val_loss: 0.1898\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1800 - val_loss: 0.1743\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1732 - val_loss: 0.1742\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1668 - val_loss: 0.1631\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1596 - val_loss: 0.1652\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 16us/step - loss: 0.1585 - val_loss: 0.1535\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1532 - val_loss: 0.1621\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1506 - val_loss: 0.1497\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 14us/step - loss: 0.1449 - val_loss: 0.1482\n",
      "Building model 27 of 27\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 2.7833 - val_loss: 0.4104\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.2693 - val_loss: 0.2190\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1992 - val_loss: 0.1837\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1787 - val_loss: 0.1730\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 13us/step - loss: 0.1694 - val_loss: 0.1664\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1639 - val_loss: 0.1612\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 12us/step - loss: 0.1587 - val_loss: 0.1560\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1546 - val_loss: 0.1531\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1511 - val_loss: 0.1510\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 11us/step - loss: 0.1481 - val_loss: 0.1479\n"
     ]
    }
   ],
   "source": [
    "# best_model = nn_grid_search(X, y, node_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the grid search has completed, we have a list of dictionaries that holds the model that gave use the highest R<sup>2</sup> score, along with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e83f62407969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the model that had the best promise, and use those parameters in a new model to find the best amount of epochs for it. After some trials, 75 epochs seemed to be the best number to use, though we were left with some slight overfitting, so an additional search will be performed with some regularization applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdict = {\n",
    "    \"first_layer_nodes\": [256],\n",
    "    \"first_dropout_rate\": [0.25, 0.5],\n",
    "    \"second_layer_nodes\": [128],\n",
    "    \"second_dropout_rate\": [0.25, 0.5],\n",
    "    \"third_layer_nodes\": [32],\n",
    "    \"third_dropout_rate\": [0.25, 0.5],\n",
    "    \"epochs\": [75]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model 1 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 6s 39us/step - loss: 2.5056 - val_loss: 0.3672\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.9568 - val_loss: 0.2869\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.8180 - val_loss: 0.2617\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.7392 - val_loss: 0.2592\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.6748 - val_loss: 0.2313\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.6359 - val_loss: 0.2231\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.6047 - val_loss: 0.2506\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5729 - val_loss: 0.2350\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.5470 - val_loss: 0.2387\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.5205 - val_loss: 0.2069\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.4967 - val_loss: 0.2032\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.4751 - val_loss: 0.2079\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.4545 - val_loss: 0.1952\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.4353 - val_loss: 0.1961\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.4179 - val_loss: 0.1917\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.4011 - val_loss: 0.1736\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3843 - val_loss: 0.1657\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3689 - val_loss: 0.1692\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.3535 - val_loss: 0.1597\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3412 - val_loss: 0.1582\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.3302 - val_loss: 0.1471\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3174 - val_loss: 0.1435\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3009 - val_loss: 0.1428\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2931 - val_loss: 0.1458\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2837 - val_loss: 0.1469\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2732 - val_loss: 0.1382\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2641 - val_loss: 0.1343\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2547 - val_loss: 0.1320\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2440 - val_loss: 0.1295\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2376 - val_loss: 0.1331\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2293 - val_loss: 0.1346\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2208 - val_loss: 0.1302\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2146 - val_loss: 0.1284\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.2082 - val_loss: 0.1268\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2030 - val_loss: 0.1222\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1966 - val_loss: 0.1272\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1888 - val_loss: 0.1286\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1865 - val_loss: 0.1233\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1806 - val_loss: 0.1152\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1747 - val_loss: 0.1198\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1725 - val_loss: 0.1161\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1671 - val_loss: 0.1156\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1622 - val_loss: 0.1204\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1586 - val_loss: 0.1169\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1566 - val_loss: 0.1169\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1536 - val_loss: 0.1144\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1510 - val_loss: 0.1189\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1491 - val_loss: 0.1140\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1460 - val_loss: 0.1115\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1435 - val_loss: 0.1081\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1424 - val_loss: 0.1147\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1392 - val_loss: 0.1112\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1378 - val_loss: 0.1062\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1379 - val_loss: 0.1126\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1356 - val_loss: 0.1105\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1337 - val_loss: 0.1112\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1347 - val_loss: 0.1175\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1318 - val_loss: 0.1160\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1332 - val_loss: 0.1033\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1303 - val_loss: 0.1065\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1293 - val_loss: 0.1069\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1292 - val_loss: 0.1074\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1281 - val_loss: 0.1020\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1281 - val_loss: 0.0997\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1266 - val_loss: 0.1015\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1278 - val_loss: 0.1046\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1265 - val_loss: 0.1020\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1265 - val_loss: 0.1042\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1260 - val_loss: 0.1034\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1232 - val_loss: 0.1011\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1255 - val_loss: 0.0990\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1231 - val_loss: 0.1003\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1230 - val_loss: 0.1035\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1237 - val_loss: 0.0983\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1221 - val_loss: 0.1013\n",
      "***Good R2 found: 90.07%***\n",
      "Building model 2 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 3.0929 - val_loss: 0.7281\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 1.1999 - val_loss: 0.7055\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.9508 - val_loss: 0.7631\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.8411 - val_loss: 0.7650\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.7586 - val_loss: 0.7721\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.6958 - val_loss: 0.7211\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.6489 - val_loss: 0.7101\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.6075 - val_loss: 0.6782\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.5742 - val_loss: 0.5800\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.5408 - val_loss: 0.5121\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 844s 6ms/step - loss: 0.5122 - val_loss: 0.4474\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 6s 44us/step - loss: 0.4912 - val_loss: 0.3944\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 6s 42us/step - loss: 0.4735 - val_loss: 0.3482\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 6s 42us/step - loss: 0.4489 - val_loss: 0.3066\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 6s 41us/step - loss: 0.4308 - val_loss: 0.2881\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 6s 44us/step - loss: 0.4127 - val_loss: 0.2762\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 6s 42us/step - loss: 0.3996 - val_loss: 0.2583\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.3867 - val_loss: 0.2576\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.3676 - val_loss: 0.2184\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.3596 - val_loss: 0.2105\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.3455 - val_loss: 0.2083\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3389 - val_loss: 0.2085\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.3259 - val_loss: 0.1945\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3151 - val_loss: 0.1836\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.3041 - val_loss: 0.1746\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2953 - val_loss: 0.1842\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2854 - val_loss: 0.1687\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.2767 - val_loss: 0.1758\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2682 - val_loss: 0.1597\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2602 - val_loss: 0.1580\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.2518 - val_loss: 0.1526\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2435 - val_loss: 0.1503\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.2382 - val_loss: 0.1480\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2311 - val_loss: 0.1487\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2242 - val_loss: 0.1481\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2191 - val_loss: 0.1388\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2135 - val_loss: 0.1429\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2071 - val_loss: 0.1389\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1986 - val_loss: 0.1405\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1943 - val_loss: 0.1387\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1918 - val_loss: 0.1373\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1862 - val_loss: 0.1359\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1837 - val_loss: 0.1328\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1797 - val_loss: 0.1268\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1776 - val_loss: 0.1294\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1735 - val_loss: 0.1308\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1704 - val_loss: 0.1254\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1671 - val_loss: 0.1270\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1643 - val_loss: 0.1252\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1642 - val_loss: 0.1205\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1598 - val_loss: 0.1241\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1605 - val_loss: 0.1280\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1580 - val_loss: 0.1241\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1555 - val_loss: 0.1208\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1555 - val_loss: 0.1202\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1519 - val_loss: 0.1170\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1495 - val_loss: 0.1213\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1502 - val_loss: 0.1161\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1490 - val_loss: 0.1182\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1482 - val_loss: 0.1193\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1461 - val_loss: 0.1192\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1454 - val_loss: 0.1175\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1468 - val_loss: 0.1180\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1446 - val_loss: 0.1146\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1442 - val_loss: 0.1123\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1428 - val_loss: 0.1109\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1435 - val_loss: 0.1087\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1417 - val_loss: 0.1135\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1424 - val_loss: 0.1137\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1407 - val_loss: 0.1094\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1409 - val_loss: 0.1076\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1404 - val_loss: 0.1112\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1396 - val_loss: 0.1084\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1394 - val_loss: 0.1147\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1383 - val_loss: 0.1080\n",
      "Building model 3 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 6s 41us/step - loss: 2.8603 - val_loss: 0.6142\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 1.1605 - val_loss: 0.5834\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.9461 - val_loss: 0.5282\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.8301 - val_loss: 0.4050\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.7499 - val_loss: 0.4065\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6863 - val_loss: 0.3309\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6370 - val_loss: 0.2939\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.5808 - val_loss: 0.2452\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.5311 - val_loss: 0.2333\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.4967 - val_loss: 0.2204\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.4620 - val_loss: 0.2274\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4378 - val_loss: 0.2079\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.4096 - val_loss: 0.1951\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3912 - val_loss: 0.1881\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3786 - val_loss: 0.1849\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.3645 - val_loss: 0.1699\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.3483 - val_loss: 0.1713\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3393 - val_loss: 0.1770\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3289 - val_loss: 0.1620\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3201 - val_loss: 0.1635\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3112 - val_loss: 0.1558\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3024 - val_loss: 0.1519\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2912 - val_loss: 0.1509\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2850 - val_loss: 0.1542\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2750 - val_loss: 0.1480\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2683 - val_loss: 0.1442\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2607 - val_loss: 0.1505\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2539 - val_loss: 0.1438\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.2460 - val_loss: 0.1420\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2390 - val_loss: 0.1476\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2331 - val_loss: 0.1450\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2272 - val_loss: 0.1461\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2203 - val_loss: 0.1429\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2157 - val_loss: 0.1487\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2105 - val_loss: 0.1393\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2040 - val_loss: 0.1444\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1989 - val_loss: 0.1423\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1951 - val_loss: 0.1396\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1901 - val_loss: 0.1477\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1867 - val_loss: 0.1448\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1833 - val_loss: 0.1449\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1809 - val_loss: 0.1466\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1777 - val_loss: 0.1473\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1736 - val_loss: 0.1510\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1722 - val_loss: 0.1374\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1691 - val_loss: 0.1471\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1659 - val_loss: 0.1549\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1660 - val_loss: 0.1378\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1630 - val_loss: 0.1394\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1609 - val_loss: 0.1437\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1589 - val_loss: 0.1431\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1575 - val_loss: 0.1459\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1568 - val_loss: 0.1385\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1548 - val_loss: 0.1370\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1523 - val_loss: 0.1343\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1507 - val_loss: 0.1371\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1503 - val_loss: 0.1379\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1492 - val_loss: 0.1348\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1494 - val_loss: 0.1333\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1476 - val_loss: 0.1360\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1467 - val_loss: 0.1260\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1453 - val_loss: 0.1307\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1456 - val_loss: 0.1270\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1437 - val_loss: 0.1316\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1452 - val_loss: 0.1400\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1421 - val_loss: 0.1273\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1433 - val_loss: 0.1266\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1430 - val_loss: 0.1342\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1404 - val_loss: 0.1232\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1402 - val_loss: 0.1237\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.1416 - val_loss: 0.1156\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1393 - val_loss: 0.1220\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1394 - val_loss: 0.1270\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.1401 - val_loss: 0.1224\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1391 - val_loss: 0.1227\n",
      "Building model 4 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 6s 46us/step - loss: 3.7948 - val_loss: 0.8782\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 1.5692 - val_loss: 0.9334\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 1.2432 - val_loss: 0.8287\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 1.1003 - val_loss: 0.8062\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.9896 - val_loss: 0.6206\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.9175 - val_loss: 0.5072\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.8169 - val_loss: 0.4770\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.7470 - val_loss: 0.4420\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.6939 - val_loss: 0.4085\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.6394 - val_loss: 0.3496\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.6029 - val_loss: 0.2934\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.5690 - val_loss: 0.2858\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.5375 - val_loss: 0.2619\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.4970 - val_loss: 0.2465\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.4627 - val_loss: 0.2278\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.4486 - val_loss: 0.2141\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4271 - val_loss: 0.2132\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.4171 - val_loss: 0.2038\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3976 - val_loss: 0.1952\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.3861 - val_loss: 0.1880\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.3726 - val_loss: 0.1872\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.3613 - val_loss: 0.1788\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.3466 - val_loss: 0.1773\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 28us/step - loss: 0.3362 - val_loss: 0.1730\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.3255 - val_loss: 0.1722\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.3161 - val_loss: 0.1613\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 6s 42us/step - loss: 0.3064 - val_loss: 0.1592\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.2987 - val_loss: 0.1627\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.2880 - val_loss: 0.1604\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2797 - val_loss: 0.1585\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2719 - val_loss: 0.1573\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2644 - val_loss: 0.1618\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2577 - val_loss: 0.1585\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2501 - val_loss: 0.1642\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.2429 - val_loss: 0.1616\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.2368 - val_loss: 0.1583\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2294 - val_loss: 0.1533\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2232 - val_loss: 0.1623\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2189 - val_loss: 0.1569\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2133 - val_loss: 0.1501\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.2102 - val_loss: 0.1587\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2049 - val_loss: 0.1529\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2011 - val_loss: 0.1559\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1967 - val_loss: 0.1544\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1915 - val_loss: 0.1468\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1871 - val_loss: 0.1452\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.1850 - val_loss: 0.1438\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1842 - val_loss: 0.1475\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.1801 - val_loss: 0.1449\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1767 - val_loss: 0.1375\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1753 - val_loss: 0.1427\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1721 - val_loss: 0.1369\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.1707 - val_loss: 0.1428\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1697 - val_loss: 0.1380\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1678 - val_loss: 0.1290\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1670 - val_loss: 0.1454\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1642 - val_loss: 0.1408\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1634 - val_loss: 0.1284\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1607 - val_loss: 0.1359\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1616 - val_loss: 0.1322\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1611 - val_loss: 0.1316\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1596 - val_loss: 0.1390\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1577 - val_loss: 0.1486\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1566 - val_loss: 0.1353\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1561 - val_loss: 0.1340\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1554 - val_loss: 0.1337\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1553 - val_loss: 0.1295\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1552 - val_loss: 0.1352\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1539 - val_loss: 0.1315\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1532 - val_loss: 0.1265\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1548 - val_loss: 0.1230\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1520 - val_loss: 0.1376\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1556 - val_loss: 0.1271\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1495 - val_loss: 0.1240\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1517 - val_loss: 0.1306\n",
      "Building model 5 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 6s 44us/step - loss: 3.3205 - val_loss: 0.5380\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 1.6474 - val_loss: 0.5033\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.4114 - val_loss: 0.4204\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.2826 - val_loss: 0.3725\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.2030 - val_loss: 0.3366\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.1310 - val_loss: 0.4062\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.0557 - val_loss: 0.3553\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.9931 - val_loss: 0.3347\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.9312 - val_loss: 0.3285\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.8801 - val_loss: 0.2833\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.8311 - val_loss: 0.2689\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 6s 42us/step - loss: 0.7848 - val_loss: 0.3070\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.7376 - val_loss: 0.2395\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6955 - val_loss: 0.2592\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.6627 - val_loss: 0.2221\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 6s 40us/step - loss: 0.6204 - val_loss: 0.2247\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 6s 40us/step - loss: 0.5890 - val_loss: 0.2092\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.5554 - val_loss: 0.2032\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.5278 - val_loss: 0.1798\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 6s 39us/step - loss: 0.5004 - val_loss: 0.1965\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.4699 - val_loss: 0.1904\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.4513 - val_loss: 0.1885\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4263 - val_loss: 0.1870\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 0.4026 - val_loss: 0.1751\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 6s 39us/step - loss: 0.3808 - val_loss: 0.1647\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.3611 - val_loss: 0.1774\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3409 - val_loss: 0.1613\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.3265 - val_loss: 0.1464\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 6s 41us/step - loss: 0.3096 - val_loss: 0.1614\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.2956 - val_loss: 0.1519\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2841 - val_loss: 0.1496\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2723 - val_loss: 0.1434\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2607 - val_loss: 0.1396\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2497 - val_loss: 0.1401\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2430 - val_loss: 0.1469\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2348 - val_loss: 0.1344\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2262 - val_loss: 0.1296\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.2212 - val_loss: 0.1308\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.2139 - val_loss: 0.1318\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2075 - val_loss: 0.1385\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.2049 - val_loss: 0.1309\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1996 - val_loss: 0.1244\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1947 - val_loss: 0.1254\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1912 - val_loss: 0.1239\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1883 - val_loss: 0.1294\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1856 - val_loss: 0.1198\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1842 - val_loss: 0.1182\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1834 - val_loss: 0.1132\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1793 - val_loss: 0.1194\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1790 - val_loss: 0.1202\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1779 - val_loss: 0.1148\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1766 - val_loss: 0.1219\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1755 - val_loss: 0.1161\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1743 - val_loss: 0.1121\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1744 - val_loss: 0.1172\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1728 - val_loss: 0.1231\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1704 - val_loss: 0.1169\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1711 - val_loss: 0.1148\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1705 - val_loss: 0.1095\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1687 - val_loss: 0.1142\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1695 - val_loss: 0.1122\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1689 - val_loss: 0.1080\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1678 - val_loss: 0.1082\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1696 - val_loss: 0.1100\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1687 - val_loss: 0.1055\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1664 - val_loss: 0.1144\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1664 - val_loss: 0.1107\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1639 - val_loss: 0.1055\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1652 - val_loss: 0.1180\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1667 - val_loss: 0.1152\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1651 - val_loss: 0.1135\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1640 - val_loss: 0.1107\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1649 - val_loss: 0.1102\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1634 - val_loss: 0.1094\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1619 - val_loss: 0.1146\n",
      "Building model 6 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 7s 50us/step - loss: 3.6219 - val_loss: 0.7676\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.8249 - val_loss: 0.8386\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.5763 - val_loss: 0.7691\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.3865 - val_loss: 0.7743\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.2605 - val_loss: 0.8039\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.1761 - val_loss: 0.7242\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 1.0980 - val_loss: 0.7234\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 1.0351 - val_loss: 0.7100\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.9721 - val_loss: 0.6204\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.9093 - val_loss: 0.5735\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.8585 - val_loss: 0.4814\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.8101 - val_loss: 0.4833\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.7427 - val_loss: 0.4286\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.7005 - val_loss: 0.3481\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.6696 - val_loss: 0.2938\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.6295 - val_loss: 0.2962\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.6021 - val_loss: 0.2836\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.5706 - val_loss: 0.2460\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.5411 - val_loss: 0.2451\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.5118 - val_loss: 0.2259\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.4869 - val_loss: 0.2067\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4628 - val_loss: 0.2165\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4428 - val_loss: 0.2097\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4198 - val_loss: 0.2081\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4002 - val_loss: 0.2046\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.3788 - val_loss: 0.1894\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.3625 - val_loss: 0.1887\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3485 - val_loss: 0.1782\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3298 - val_loss: 0.1727\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3164 - val_loss: 0.1716\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3001 - val_loss: 0.1640\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2899 - val_loss: 0.1640\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2765 - val_loss: 0.1549\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2698 - val_loss: 0.1632\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2569 - val_loss: 0.1529\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2510 - val_loss: 0.1585\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2420 - val_loss: 0.1418\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2360 - val_loss: 0.1482\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2303 - val_loss: 0.1427\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2251 - val_loss: 0.1393\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2184 - val_loss: 0.1401\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2136 - val_loss: 0.1433\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2104 - val_loss: 0.1364\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2073 - val_loss: 0.1327\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2026 - val_loss: 0.1505\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2010 - val_loss: 0.1434\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1987 - val_loss: 0.1282\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1961 - val_loss: 0.1372\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.1941 - val_loss: 0.1431\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1943 - val_loss: 0.1353\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1918 - val_loss: 0.1267\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1894 - val_loss: 0.1363\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1899 - val_loss: 0.1362\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.1886 - val_loss: 0.1274\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1864 - val_loss: 0.1329\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1832 - val_loss: 0.1307\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1823 - val_loss: 0.1258\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1834 - val_loss: 0.1263\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.1816 - val_loss: 0.1265\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1825 - val_loss: 0.1284\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.1818 - val_loss: 0.1269\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1801 - val_loss: 0.1235\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1795 - val_loss: 0.1160\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 0.1795 - val_loss: 0.1180\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.1794 - val_loss: 0.1218\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1776 - val_loss: 0.1160\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1767 - val_loss: 0.1215\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1765 - val_loss: 0.1203\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1781 - val_loss: 0.1178\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1784 - val_loss: 0.1191\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1770 - val_loss: 0.1198\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1755 - val_loss: 0.1164\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1739 - val_loss: 0.1175\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1743 - val_loss: 0.1304\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.1766 - val_loss: 0.1223\n",
      "Building model 7 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 6s 45us/step - loss: 3.5808 - val_loss: 0.8408\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.6855 - val_loss: 0.6833\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.4355 - val_loss: 0.5736\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.2857 - val_loss: 0.4416\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 5s 38us/step - loss: 1.1549 - val_loss: 0.4331\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 1.0708 - val_loss: 0.4260\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.9772 - val_loss: 0.2945\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.8992 - val_loss: 0.2980\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.8547 - val_loss: 0.2973\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.7857 - val_loss: 0.2938\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.7444 - val_loss: 0.2602\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6935 - val_loss: 0.2310\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6508 - val_loss: 0.2308\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6170 - val_loss: 0.2307\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5884 - val_loss: 0.2134\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5598 - val_loss: 0.2167\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5320 - val_loss: 0.1987\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5059 - val_loss: 0.1952\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.4857 - val_loss: 0.1827\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4611 - val_loss: 0.1939\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.4445 - val_loss: 0.1824\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4224 - val_loss: 0.1697\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4044 - val_loss: 0.1703\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3872 - val_loss: 0.1665\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3704 - val_loss: 0.1601\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.3572 - val_loss: 0.1596\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3433 - val_loss: 0.1643\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3276 - val_loss: 0.1568\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3140 - val_loss: 0.1512\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3043 - val_loss: 0.1489\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2912 - val_loss: 0.1389\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2817 - val_loss: 0.1368\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2736 - val_loss: 0.1457\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2653 - val_loss: 0.1424\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2590 - val_loss: 0.1343\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.2493 - val_loss: 0.1363\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2417 - val_loss: 0.1353\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2355 - val_loss: 0.1244\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2328 - val_loss: 0.1324\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2272 - val_loss: 0.1271\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2222 - val_loss: 0.1308\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2180 - val_loss: 0.1339\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2145 - val_loss: 0.1209\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2142 - val_loss: 0.1300\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2074 - val_loss: 0.1280\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2038 - val_loss: 0.1222\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2059 - val_loss: 0.1221\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2018 - val_loss: 0.1228\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1971 - val_loss: 0.1277\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1967 - val_loss: 0.1153\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1946 - val_loss: 0.1172\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1917 - val_loss: 0.1249\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1949 - val_loss: 0.1152\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1917 - val_loss: 0.1201\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1907 - val_loss: 0.1177\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1894 - val_loss: 0.1225\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1889 - val_loss: 0.1178\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1870 - val_loss: 0.1176\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1880 - val_loss: 0.1124\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1878 - val_loss: 0.1173\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1872 - val_loss: 0.1122\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1869 - val_loss: 0.1196\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1833 - val_loss: 0.1167\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1850 - val_loss: 0.1174\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1827 - val_loss: 0.1126\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.1833 - val_loss: 0.1182\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1812 - val_loss: 0.1152\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1814 - val_loss: 0.1154\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.1816 - val_loss: 0.1127\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 5s 37us/step - loss: 0.1821 - val_loss: 0.1114\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1817 - val_loss: 0.1085\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.1782 - val_loss: 0.1128\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1799 - val_loss: 0.1100\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1784 - val_loss: 0.1098\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.1775 - val_loss: 0.1147\n",
      "Building model 8 of 8\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 6s 44us/step - loss: 3.6126 - val_loss: 1.7920\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.8524 - val_loss: 1.3186\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 1.5096 - val_loss: 1.0780\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.2923 - val_loss: 0.8128\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 1.1580 - val_loss: 0.6719\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 1.0269 - val_loss: 0.6225\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.9255 - val_loss: 0.5364\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.8454 - val_loss: 0.4418\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.7776 - val_loss: 0.4037\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.7284 - val_loss: 0.3566\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6809 - val_loss: 0.3201\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.6390 - val_loss: 0.2997\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.6058 - val_loss: 0.2850\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5774 - val_loss: 0.2532\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5502 - val_loss: 0.2489\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5239 - val_loss: 0.2201\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.5016 - val_loss: 0.2321\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.4761 - val_loss: 0.2273\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4534 - val_loss: 0.2124\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4386 - val_loss: 0.1963\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4200 - val_loss: 0.1831\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.4031 - val_loss: 0.1857\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3894 - val_loss: 0.1833\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3750 - val_loss: 0.1831\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3598 - val_loss: 0.1640\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3502 - val_loss: 0.1669\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.3363 - val_loss: 0.1642\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3250 - val_loss: 0.1607\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3121 - val_loss: 0.1642\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.3042 - val_loss: 0.1563\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2950 - val_loss: 0.1518\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2862 - val_loss: 0.1536\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2791 - val_loss: 0.1446\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2692 - val_loss: 0.1447\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2664 - val_loss: 0.1502\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2607 - val_loss: 0.1531\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2530 - val_loss: 0.1464\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2467 - val_loss: 0.1387\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2465 - val_loss: 0.1408\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2400 - val_loss: 0.1418\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2358 - val_loss: 0.1420\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2345 - val_loss: 0.1459\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2307 - val_loss: 0.1430\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2313 - val_loss: 0.1354\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2287 - val_loss: 0.1449\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2261 - val_loss: 0.1499\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2237 - val_loss: 0.1372\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.2200 - val_loss: 0.1332\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2202 - val_loss: 0.1328\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2178 - val_loss: 0.1376\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2179 - val_loss: 0.1365\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2151 - val_loss: 0.1362\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.2150 - val_loss: 0.1317\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2147 - val_loss: 0.1372\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2123 - val_loss: 0.1320\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2128 - val_loss: 0.1317\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2142 - val_loss: 0.1310\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2121 - val_loss: 0.1318\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.2105 - val_loss: 0.1387\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 0.2108 - val_loss: 0.1281\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 0.2104 - val_loss: 0.1297\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 5s 35us/step - loss: 0.2100 - val_loss: 0.1219\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2087 - val_loss: 0.1311\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2088 - val_loss: 0.1287\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2058 - val_loss: 0.1300\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2063 - val_loss: 0.1240\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2068 - val_loss: 0.1299\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2050 - val_loss: 0.1280\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.2056 - val_loss: 0.1293\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2041 - val_loss: 0.1253\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 0.2054 - val_loss: 0.1280\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2049 - val_loss: 0.1229\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 4s 32us/step - loss: 0.2021 - val_loss: 0.1223\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.2036 - val_loss: 0.1184\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 0.2036 - val_loss: 0.1206\n"
     ]
    }
   ],
   "source": [
    "final_model = nn_grid_search(X, y, grid_params=pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_model': <keras.engine.sequential.Sequential at 0x1a557d7d10>,\n",
       " 'best_score': 0.900713765015688,\n",
       " 'best_params': {'first_layer_nodes': 256,\n",
       "  'first_dropout_rate': 0.25,\n",
       "  'second_layer_nodes': 128,\n",
       "  'second_dropout_rate': 0.25,\n",
       "  'third_layer_nodes': 32,\n",
       "  'third_dropout_rate': 0.25,\n",
       "  'epochs': 75},\n",
       " 'best_history': <keras.callbacks.History at 0x1a57ce6550>,\n",
       " 'test_preds': array([[5.648533 ],\n",
       "        [4.497038 ],\n",
       "        [3.839902 ],\n",
       "        ...,\n",
       "        [5.1945095],\n",
       "        [4.4716697],\n",
       "        [3.4207933]], dtype=float32)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_preds = final_model[\"best_model\"].predict(X_train_sc)\n",
    "nn_test_preds = final_model[\"test_preds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907672063389299"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_train, nn_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8817637469051529"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, nn_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = final_model[\"best_history\"].history[\"loss\"]\n",
    "test_loss = final_model[\"best_history\"].history[\"val_loss\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model\n",
    "model = Sequential()\n",
    "\n",
    "# adding layers\n",
    "model.add(Dense(128,\n",
    "               activation=\"relu\",\n",
    "               input_shape=(X_train_sc.shape[1],)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compiling model to optimize MSE\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "             optimizer=\"adam\")\n",
    "\n",
    "# setting and early stopper\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0005,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 128)               23296     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33,665\n",
      "Trainable params: 33,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# getting overview of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/10\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 1.8233 - val_loss: 0.2355\n",
      "Epoch 2/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.2180 - val_loss: 0.1872\n",
      "Epoch 3/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1843 - val_loss: 0.1711\n",
      "Epoch 4/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1659 - val_loss: 0.1612\n",
      "Epoch 5/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1580 - val_loss: 0.1558\n",
      "Epoch 6/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1528 - val_loss: 0.1503\n",
      "Epoch 7/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1499 - val_loss: 0.1473\n",
      "Epoch 8/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1461 - val_loss: 0.1492\n",
      "Epoch 9/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1438 - val_loss: 0.1429\n",
      "Epoch 10/10\n",
      "141859/141859 [==============================] - 2s 15us/step - loss: 0.1418 - val_loss: 0.1413\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=1024,\n",
    "                    validation_data=(X_test_sc, y_test),\n",
    "                   callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-105db6cc38cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "train_preds = history.model.predict(X_train_sc)\n",
    "test_preds = history.model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-b18456caed8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_preds' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7b2a5f0923f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of our models\n",
    "models = [cvec_lr_grid, tf_lr_grid, tf_knn_grid, tf_mnb_grid, tf_rf_grid, cvec_boost_grid, tf_boost_grid]\n",
    "\n",
    "# putting each model variation into the df\n",
    "model_df[\"model\"] = [f\"{model.estimator.steps[0][0]}, {model.estimator.steps[1][0]}\" for model in models]\n",
    "\n",
    "# putting in the training scores\n",
    "model_df[\"train_r2\"] = [round(model.score(X_train, y_train), 3) for model in models]\n",
    "\n",
    "# putting in the testing scores\n",
    "model_df[\"test_r2\"] = [round(model.score(X_test, y_test), 3) for model in models]\n",
    "\n",
    "# getting the difference, or variance, between each score\n",
    "model_df[\"var\"] = model_df[\"train_acc\"] - model_df[\"test_acc\"]\n",
    "\n",
    "# checking the final dataframe\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R<sup>2</sup> Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate both the normal R<sup>2</sup>, and adjusted R<sup>2</sup> scores for each of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bringing in custom adjusted r2 function from 3.01 Linear Reg Lab\n",
    "def r2_adj(model, X, y):\n",
    "    # seting some base variables\n",
    "    n = len(y)\n",
    "    k = len(X.columns)\n",
    "    r_sq = model.score(X, y)\n",
    "    \n",
    "    # using the vars as inputs for the adjusted r2 equation\n",
    "    r_sq_adj = 1 - (((1 - r_sq) * (n - 1)) / (n - k - 1))\n",
    "    return r_sq_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO train MSE: 1006.7210399896342.\n",
      "LASSO test MSE: 1067.9519777748644.\n"
     ]
    }
   ],
   "source": [
    "# finding mse for lasso model\n",
    "\n",
    "# making predictions\n",
    "lasso_train_preds = np.exp(lasso_model.predict(X_train_sc))\n",
    "lasso_test_preds = np.exp(lasso_model.predict(X_test_sc))\n",
    "\n",
    "# calculating mse\n",
    "lasso_train_mse = metrics.mean_squared_error(np.exp(y_train), lasso_train_preds)\n",
    "lasso_test_mse = metrics.mean_squared_error(np.exp(y_test), lasso_test_preds)\n",
    "\n",
    "print(f\"LASSO train MSE: {lasso_train_mse}.\")\n",
    "print(f\"LASSO test MSE: {lasso_test_mse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141859,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141859,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(linreg_model.predict(X_train_sc)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.728700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.903115e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.585609e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.963497e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.379830e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.673716e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.366105e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.364020e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  4.728700e+04\n",
       "mean   8.903115e+06\n",
       "std    1.585609e+09\n",
       "min   -7.963497e+10\n",
       "25%    3.379830e+00\n",
       "50%    3.673716e+00\n",
       "75%    4.366105e+00\n",
       "max    2.364020e+11"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(data=linreg_test_preds)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47287,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(linreg_model.predict(X_test_sc)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS train MSE: 4896.633713226849.\n",
      "OLS test MSE: 2.514182837648352e+18.\n"
     ]
    }
   ],
   "source": [
    "# finding mse for lasso model\n",
    "\n",
    "# making predictions\n",
    "linreg_train_preds = np.exp(linreg_model.predict(X_train_sc))\n",
    "linreg_test_preds = linreg_model.predict(X_test_sc)\n",
    "\n",
    "# calculating mse\n",
    "linreg_train_mse = metrics.mean_squared_error(y_train, linreg_train_preds)\n",
    "linreg_test_mse = metrics.mean_squared_error(y_test, linreg_test_preds)\n",
    "\n",
    "print(f\"OLS train MSE: {linreg_train_mse}.\")\n",
    "print(f\"OLS test MSE: {linreg_test_mse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[[\"train_r2\", \"test_r2\"]].plot(kind=\"bar\",\n",
    "                                        figsize=(9, 6),\n",
    "                                        rot=0)\n",
    "plt.title(\"R2 Scores by Model\", size=20)\n",
    "plt.ylabel(\"Score\", size=15)\n",
    "plt.xlabel(\"Model Name\", size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a8292a610>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trasnforming y back to actual sizes\n",
    "y_test_gram = np.exp(y_test)\n",
    "pred_test_gram = np.exp(nn_test_preds.reshape(-1,))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# showing a scatter plot of the predicted vs actual serving sizes\n",
    "sns.scatterplot(y_test_gram, pred_test_gram)\n",
    "\n",
    "# setting the visuals\n",
    "plt.title(\"Underprediction of Serving Sizes\", size=20)\n",
    "plt.xlabel(\"Actual Serving Size (g)\", size=15)\n",
    "# plt.xticks(list(range(0, 600_001, 75_000)))\n",
    "plt.ylabel(\"Predicted Serving Size (g)\", size=15)\n",
    "# plt.yticks(list(range(0, 600_001, 75_000)))\n",
    "plt.plot(y_test_gram, y_test_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this comparison of predicted and actual serving sizes that our model has a clear tendency to underpredict servings as the real serving size increases. There could be several reasons behind why this is happening, though one clear and logical answer may be that some of those foods with larger serving sizes have larger portions of the food that are inedible. This could mean a food that has shells or pits, or something else that is counted in the total weight, but is not eaten. Unfortunately, these aspects were not accounted for in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a neural network gave use the best results overall. It was able to increase the R<sup>2</sup> score above 90%, and still limit variance to less than 2%. It was also able to minimize MSE better than the other models that were made.\n",
    "This model only takes certain attributes into account, and there are many other factors that can have an impact on serving size, such as package size, sale price, or targeted demographic. Many of these factors can be proprietary information to the manufacturing company, and are unavailable to the public, making a deeper analysis difficult. This could, however, be adapted within a specific company to account for some of these features, or to be trained on a more specific set of foods products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main recommendations for this project would be to conduct further analysis of the vectorized ingredients. Utilizing the ingredients as features did not appear to help our models in the current scope, though with more time to optimize, they may be able to improve the model further.\n",
    "\n",
    "Another interesting step to take would be to perform PCA on the nutrient features. \n",
    "\n",
    "Further utilization of the neural network grid search function. The project timeline and available computing power were severe limits on fully fleshing out the neural network. Of course the possibilities are truly endless, but even within the scope of layers, nodes, and regularization that were searched through here, there is most likely further optimization that could be done.\n",
    "\n",
    "Another modeling option could be to use a support vector machine (SVM), as this may be a more fitting model for this type of data. Unfortunately, due to the large amount of data and features being used, there was once again a computing power issue preventing this type of model from being run.\n",
    "\n",
    "Overall, the computational issues in this project could possibly be overcome by utilizing cloud computing services, such as those available on Amazon Web Services, or perhaps even just using a more powerful home computer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
